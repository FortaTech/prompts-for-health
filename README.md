# Prompts-for-Health
**Helpful prompts to transform the way healthcare professionals use generative AI such as ChatGPT and BastionGPT.**

Welcome to the Prompts-For-Health repository! This collection of AI prompts, which are tasks and instructions that can be given to generative AI, is dedicated to providing healthcare professionals with an array of safe, innovative, and transformative conversation prompts. These prompts are designed to facilitate more efficient, empathetic, and constructive interactions with patients, helping to bridge communication gaps, unearth crucial health insights, and empower healthcare professionals to spend less time documenting and more time providing quality patient care.


## How to Use
**For Healthcare Professionals**
Browse through the categories and find prompts that resonate with your needs. Each prompt comes with guidelines on how it could be used, the objectives it serves, potential follow-up questions, and literature supporting its efficacy.

**Contributions**
We encourage healthcare professionals, AI enthusiasts, communication experts, and even patients with insights into effective communication to contribute to this repository. Before contributing a prompt, please check to see if a similar prompt already exists. If it does, we recommend enhancing the existing one with comments or revisions. You can contribute directly to the project via the instructions below, or you can reach out to FortaTech or another contributor.

To contribute directly, follow these steps:

- Fork the repository.
- Create a new branch in your forked repository.
- Add your prompt in the relevant category following the PROMPT_TEMPLATE.md format.
- Submit a pull request against the main branch of the original Prompts-For-Health repository.
- All submissions are reviewed by moderators before they're accepted and merged into the repository. This review includes a check for safety, appropriateness, clarity, and healthcare basis.

## Safe and Responsible AI Principles
As pioneers in healthcare technology, we recognize the crucial role we play in incorporating artificial intelligence into healthcare workflows. We firmly support and align to leading AI ethical and safety principles.

- [G20 AI Principles](https://oecd.ai/en/ai-principles)
- [‍Microsoft Responsible AI Principles](https://www.microsoft.com/en-us/ai/principles-and-approach)
- [NIST AI Risk Management Framework](https://www.nist.gov/itl/ai-risk-management-framework)

### Our Healthcare Generative AI Principles
We have established a complimentary, and more focused set of principles, specific to healthcare generative AI, that act as our north star to guide our innovative journey to elevate patient care and reduce healthcare workforce burnout, focusing unwaveringly on the safety, privacy, and well-being of patients.
These principles aim to foster trust and transparency with our diverse community and reflect our steadfast commitment to maintaining the highest standards of integrity, accuracy, and reliability in our services. We encourage other organizations to embrace these guidelines, helping to realize a safe and transformative integration of technology and healthcare, with medical professionals at the forefront, ensuring a human-centric and ethical approach to patient care.


**Principle 5: Guard Patient Interaction**
> “Generative AI must not directly provide medical advice to patients unless monitored and strictly validated.”

Generative AI is advancing rapidly, creating boundless possibilities. However, when it comes to providing medical advice, these solutions should not directly communicate with patients unless the outputs are strictly controlled and thoroughly vetted by both industry experts and the relevant regulatory bodies. The distinct risk of AI hallucinations and biases in healthcare topics necessitates medical professionals, who are trained and experienced, to supervise interactions. Medical professionals are essential in ensuring the accuracy and reliability of the advice given, recognizing the limitations of AI, and preventing potential harm to patients.
‍

**Principle 4: Uphold Privacy and Security**
> “All personally identifiable information must be kept private and secure.”

The influx of insecure AI services, often cheaper and below standard, poses significant risks to the security and privacy of sensitive personal information. The integrity and confidentiality of patient information must never be compromised. All AI healthcare services must align with healthcare standards and comply with regulatory requirements to avoid breaches that could jeopardize patient wellbeing. Establishing robust privacy controls and security measures are critical in maintaining trust and safeguarding patient interests.
‍

‍**Principle 3: Prioritize Evidence-Based Medicine**
> “Source data for generative AI must prioritize evidence-based medicine and reputable sources.”

Misinformation and biases are prevalent, even in reputable sources across the internet. Generative AI in healthcare must be anchored in evidence-based medicine, relying on trusted, scientific sources to inform its knowledge base. A stringent, proactive approach is essential to mitigate the risk of circulating harmful and inaccurate data points, improving the accuracy, reliability, and safety of the AI-generated outputs.

‍
**Principle 2: Promote Transparency and Caution**
> “Generative AI must transparently communicate its propensity for errors even when used by medical professionals.”

The incredible capabilities of generative AI can lead to a false sense of security and overshadow its inherent limitations and potential for mistakes. It is crucial to maintain transparency about AI’s limitations and encourage both users to approach the AI outputs with caution and critical evaluation. The emphasis should be on ensuring the responsible use of AI, with medical professionals maintaining vigilance and scrutiny to detect any inaccuracies, thereby preventing potential harm to patients.


**Principle 1: Maintain Human Oversight**
> “A medical professional must mediate the provision of medical advice or information from AI to patients.”

The interface between AI and patients, especially in delivering medical advice or information, must be sufficiently supervised by medical professionals unless appropriate safeguards are robustly implemented. These safeguards can include strict governance around AI outputs, ongoing monitoring by healthcare professionals, and rigorous validation of medical accuracy. We must keep healthcare human-centric, with clinicians retaining control to ensure the safety, accuracy, and appropriateness of the advice provided.


‍
## License
This project is licensed under the terms of the MIT license.


## Disclaimer
The prompts within this repository are illustrative use cases that have been screened to reduce the risk of harm and are intended for use by healthcare professionals. However, users must be aware of the risks that come with the use of Large Language Models (LLMs) like BastionGPT and ChatGPT. LLMs may occasionally provide inaccurate or inappropriate responses. All users must review the responses from LLMs for accuracy and appropriateness prior to use in any healthcare setting, such as entry into an electronic medical record or communication with a patient. 

While these prompts provide value in various healthcare applications, users should be aware of several limitations and risks inherent to the AI:

- **Hallucination:** BastionGPT, despite its sophisticated learning algorithms, can produce "hallucinated" responses—information that appears plausible but is incorrect or not based in reality. This can occur even when the input data is both accurate and unambiguous. In the healthcare environment, this could lead to misleading or inaccurate health information, which could pose serious risks if not properly understood and managed.
- **Biases:** Despite extensive training and regular updates, BastionGPT can sometimes exhibit unintended biases. These biases are reflections of the biases present in the data it was trained on and not an intentional feature of the model. While we strive to minimize these, they may still occur and could potentially influence the model's responses.
- **Outdated Information:** As of the AI model's informaiton cut-off, most AI does not have the capability to update its knowledge base with real-time information or developments. Consequently, any advancements, changes in guidelines, or novel treatments emerging in the healthcare industry post this date may not be reflected in the responses of AI.


## Support
If you're experiencing any issues, have questions, or simply wish to connect with the core team, please feel free to open an issue in this repository or reach out to us at hello@forta.tech.
